[
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "learnings.html",
    "href": "learnings.html",
    "title": "Learnings",
    "section": "",
    "text": "Prior to this course, I had very minimal coding experience. Now I have a better understanding of programming with python and setting up a coding environment and handeling it.\nI learned following tools and topics:\n\nhow to set up an virtual environment\nbasics of (Power Shell) commands/ terminal\npython basics\njupyter notebooks\nanaconda as a package management tool\nquarto\nstreamlit\nthe python libraries altair and pandas\nsassy css (scss)\nyml\n\nWhile working with jupyter notebooks, I realized how important it is to keep a clean folder structure inside the project. That is why I created a cleaned data and an original data folder inside my code folder. After reading the data files into the notebooks and cleaning them, I saved them inside the cleaned data folder to avoid confusion and to run the notebooks smoothly.\n\n\n\n\nBecause my Data Literacy course from semester 1 and 2 was a while ago, I refreshed my knowledge on Data Science/ Statistics.\nI now know helpful websites where you can get inspiration for data visualizations, like From Data to Viz.\nThe Data Storytelling Principles (Knaflic 2015):\n\nunderstand the context/ your audience\nchoose an effective visual\neliminate clutter\nfocus attention\ntell a story\n\n\n\n\n\nKnaflic, Cole Nussbaumer. 2015. Storytelling with Data. https://doi.org/10.1002/9781119055259."
  },
  {
    "objectID": "learnings.html#coding-and-coding-environment",
    "href": "learnings.html#coding-and-coding-environment",
    "title": "Learnings",
    "section": "",
    "text": "Prior to this course, I had very minimal coding experience. Now I have a better understanding of programming with python and setting up a coding environment and handeling it.\nI learned following tools and topics:\n\nhow to set up an virtual environment\nbasics of (Power Shell) commands/ terminal\npython basics\njupyter notebooks\nanaconda as a package management tool\nquarto\nstreamlit\nthe python libraries altair and pandas\nsassy css (scss)\nyml\n\nWhile working with jupyter notebooks, I realized how important it is to keep a clean folder structure inside the project. That is why I created a cleaned data and an original data folder inside my code folder. After reading the data files into the notebooks and cleaning them, I saved them inside the cleaned data folder to avoid confusion and to run the notebooks smoothly."
  },
  {
    "objectID": "learnings.html#data-literacy-data-storytelling",
    "href": "learnings.html#data-literacy-data-storytelling",
    "title": "Learnings",
    "section": "",
    "text": "Because my Data Literacy course from semester 1 and 2 was a while ago, I refreshed my knowledge on Data Science/ Statistics.\nI now know helpful websites where you can get inspiration for data visualizations, like From Data to Viz.\nThe Data Storytelling Principles (Knaflic 2015):\n\nunderstand the context/ your audience\nchoose an effective visual\neliminate clutter\nfocus attention\ntell a story\n\n\n\n\n\nKnaflic, Cole Nussbaumer. 2015. Storytelling with Data. https://doi.org/10.1002/9781119055259."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Preface",
    "section": "",
    "text": "Preface\nWelcome!\nThis is my project documentation for the Data Storytelling course in the winter semester of 2023/2024.  In this project, I created a fictional company ‚ÄúUrban Butcher‚Äù, collected data from public data sets and formed a ‚ÄúBig Idea‚Äù for an recommended action based on the data analysis.\nMy Big Idea: In order to remain competitive, improve its environmental footprint and promote a sustainable image among customers, Urban Butcher should expand its product range to include plant-based alternatives.\nThe data visualizations which were used to communicate this Big Idea are realised with the python libraries pandas and altair, presented on quarto and streamlit."
  },
  {
    "objectID": "data-story.html",
    "href": "data-story.html",
    "title": "The Story",
    "section": "",
    "text": "For the presentation, I decided to tell a chronological story, because my recommendation is pretty drastical for a butcher shop (vegan products in a butchery!). I did not lead with my ending and rather tried to introduce my audience slowly to the topic of sustainablility.\nMy narrative arc for the presentation:"
  },
  {
    "objectID": "data-story.html#presentation",
    "href": "data-story.html#presentation",
    "title": "The Story",
    "section": "",
    "text": "For the presentation, I decided to tell a chronological story, because my recommendation is pretty drastical for a butcher shop (vegan products in a butchery!). I did not lead with my ending and rather tried to introduce my audience slowly to the topic of sustainablility.\nMy narrative arc for the presentation:"
  },
  {
    "objectID": "alt-protein.html",
    "href": "alt-protein.html",
    "title": "Alt-Protein Companies",
    "section": "",
    "text": "Source: The Good Food Institute\nThis website provides a data set with companies producing ingredients or equipment for alternative protein products.\nüîó To the dataset\n\n\nInteresting metrics in the data set for the storyline:\n\ncompany focus (e.g.¬†meat, dairy alternative)\nCountry/ region\nYear founded\n\nPossible insights:\n\ngrowth in recent years (e.g.¬†after 2010)\nthere are a lot of companys providing alternatives\nmaybe comparing countries?\nindicating/ fitering by product type\n(There are Logos in the database, could be cool to use?)\nthe distribution of companies across the globe\n\nAlso: In the data set, there is ‚Äúcultivated meat‚Äù under the category ‚Äúprotein category‚Äù.\n‚Üí filter to only ‚Äúplant-based‚Äù\nLastly, this data set is updated per request. This could be dangerous, because there is no transparent way to see when the data set was updated last and (I am fairly sure) there is no claim to completeness.\n\n\n\n\n\n\n\n\n\n\nIdea: compare the falling meat consumption with the (hopefully) rising emerging alt-protein companies\n\n\n\n\nImplementation:\n\nGrouping the data set by the Country/ Region column\n\ndf_country = df.groupby('Country/Region').size().reset_index(name='Number of Companies per Country')\n\nHere comes the problem: I do not have the latitude nor longitude inside my dataset. My only indicators are the Country Names. I can not plot my chart as seen in the Altair Documentation of a Choropleth Map, I do not have a cloumn with the iso-3166 code which altair uses to perform the lookup on the geoshape.\nI tried to download a csv file containing the iso codes, to merge with my df, but this did not work properly\nWorkaround: I found a really helful Git Hub repository  Github bast . With the help of this code (which firstly transforms the csv with the iso-codes to the name, and then this name to our value!) I could plot my visualization.\n\n## ----!!! Source:  https://github.com/bast/altair-geographic-plots/blob/main/choropleth.ipynb ---- ##\n\ncountries = alt.topo_feature(data.world_110m.url, \"countries\")\n# https://en.wikipedia.org/wiki/ISO_3166-1_numeric\ncountry_codes = pd.read_csv(\n    \"https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv\"\n)\n\nbackground = alt.Chart(countries).mark_geoshape(fill=\"lightgray\")\n\n# we transform twice, first from \"ISO 3166-1 numeric\" to name, then from name to value\nforeground = (\n    alt.Chart(countries)\n    .mark_geoshape()\n    .transform_lookup(\n        lookup=\"id\",\n        from_=alt.LookupData(data=country_codes, key=\"country-code\", fields=[\"name\"]),\n    )\n    .transform_lookup(\n        lookup=\"name\",\n        from_=alt.LookupData(data=df_country, key=\"name\", fields=[\"Number of Companies per Country\"]),\n    )\n    .encode(\n        fill=alt.Color(\n            \"Number of Companies per Country:Q\",\n            scale=alt.Scale(scheme=\"reds\"),\n            title=\"Number of Companies\"\n        ),\n        tooltip=[alt.Tooltip('name:N', title='Country'), alt.Tooltip('Number of Companies per Country:Q', title='Number of Companies')]\n    )\n)\n\nchart = (\n    (background + foreground)\n    .properties(width=700, height=600)\n    .project(\n        type=\"equalEarth\",\n        scale=800,\n        translate=[200,1000],\n    )\n)\n\n\nIn the visualization, I realized some countries were not displayed. This was due to the fact, that some Countries in my df were not cohesive with the names in the csv file. I decided, I will only show a visualization of europe (adjusting the scale and translation) and edit the incorrect names manually.\n\nEuropean countries in df_country affected:\n\nBavaria and Scotland (can be dropped, only one Company in each)\nCzech Republic -&gt; in country_code file: Czechia\nUnited Kingdom -&gt; in country_code file: United Kingdom of Great Britain and Northern Ireland\n\nFinal Chart:\n\n\n\n\nImplementation:\n\nCleaning the data, dropping non relevant columns and changing the data types\n\n# dropping not interesting cloumns, e.g. website, founders, ...\n\ndf.drop(['Brief Description', 'Animal-Type Analog', 'State', 'City', 'Website', 'Founders'], axis=1, inplace=True)\n\nLIST_CAT = ['Protein Category','Company Focus','Company type','Technology Focus','Product Type','Ingredient Type','Operating Regions','Country/Region']\n\nfor i in LIST_CAT:\n    df[i] = df[i].astype('category')\n\nCreating a new df with companies specialized on alternative proteins, grouped by Year Founded\n\ndf_founded = df[df['Company type'] == 'Specialized (focused on alternative proteins)'].groupby('Year Founded').size().reset_index(name='Number of Companies Founded')\n\nDecission: I will use the data up until 2021, because it fits better with the meat consumption data & fits better in the storyline\n\ndf_founded = df_founded[(df_founded['Year Founded'] &gt;= 2010) & (df_founded['Year Founded'] &lt;= 2021)]\n\n\n\nYear Founded\nNumber of Companies Founded\n\n\n\n\n2010\n18\n\n\n2011\n19\n\n\n2012\n20\n\n\n2013\n24\n\n\n2014\n27\n\n\n2015\n45\n\n\n2016\n54\n\n\n2017\n66\n\n\n2018\n77\n\n\n2019\n109\n\n\n2020\n105\n\n\n2021\n95\n\n\n\n\nPlotting the line chart\n\n# Convert year founded to datetime\n\ndf_founded['Year Founded'] = pd.to_datetime(df_founded['Year Founded'], format='%Y')\n\n# Plotting line chart\n\nline_chart = alt.Chart(df_founded\n).mark_line().encode(\n    x=alt.X('Year Founded').axis(\n        title = \"Year\",\n        titleColor = 'grey',\n        titleAnchor='start',\n        labelAngle = 0,\n        grid = False,\n        tickColor= 'grey'), \n    y= alt.Y('Number of Companies Founded').axis(\n        title ='Number of Companies Founded',\n        titleColor= 'grey',\n        titleAnchor='end',\n        grid = False, \n        tickColor= 'grey', \n    ),\n    strokeWidth = alt.value(2)\n).properties(\n    width = 550,\n    height = 350\n)\nFinal Chart:\n\n\n\n\nImplementation (in the quarto presentation file):\n\nMerging the dataframes of the meat consumption and alt-protein companies founded\n\ndf_merged = pd.merge(df_consumption, df_founded,\n                     left_on='Year', right_on='Year Founded')\n\nDelete one of the ‚ÄúYear‚Äù columns, otherwise it would be double\nUsing the Altair Documentation of a layered chart with dual axis as a reference\n\n# create double axis chart\nbase = alt.Chart(df_merged).encode(\n    x=alt.X('Year:T').axis(\n        title=\"Year\",\n        titleColor='grey',\n        titleAnchor='start',\n        labelAngle=0,\n        grid=False,\n        tickColor='grey',\n        format='%Y'),\n    strokeWidth=alt.value(2)\n).properties(\n    width=750,\n    height=400\n)\n\nline_consumption = base.mark_line(stroke=dark_red).encode(\n    x=alt.X('Year:T').axis(\n        grid=False,\n        titleColor='grey',\n        titleAnchor='start'),\n    y=alt.Y('Consumption per Person:Q').scale(domain=(40, 75)).axis(\n        title='Consumption of Meat per Person in Germany (kg)',\n        titleColor=dark_red,\n        grid=False,\n        titleAnchor='end',\n        titleAngle=270,\n        titleX=50,\n    )\n)\n\nline_founded = base.mark_line(stroke=blue_highlight).encode(\n    x=alt.X('Year:T').axis(\n        grid=False,\n        titleColor='grey',\n        titleAnchor='start'),\n    y=alt.Y('Number of Companies Founded:Q').axis(\n        title='Number of Companies Founded',\n        titleColor=blue_highlight,\n        grid=False,\n        titleAnchor='end'\n    )\n)\n\nNote here: I left out the year 2022, even though there was meat consumption data that year, in both datasets (alt-protein-companies and meat-consumption). Reason for that was the very low Number of Companies founded in the year 2022. My presumtion is, that this is due to the fact that the Good Food Institute Data set is updated on submission. Newer companies were maybe not yet added to the data. Overall, the comparision with another dataset, maybe regarding the consumption of alternative protein products in Germany, would have been a lot more fitting. Sadly, I could not find any open data sets regarding that topic."
  },
  {
    "objectID": "alt-protein.html#explorative-data-analysis",
    "href": "alt-protein.html#explorative-data-analysis",
    "title": "Alt-Protein Companies",
    "section": "",
    "text": "Interesting metrics in the data set for the storyline:\n\ncompany focus (e.g.¬†meat, dairy alternative)\nCountry/ region\nYear founded\n\nPossible insights:\n\ngrowth in recent years (e.g.¬†after 2010)\nthere are a lot of companys providing alternatives\nmaybe comparing countries?\nindicating/ fitering by product type\n(There are Logos in the database, could be cool to use?)\nthe distribution of companies across the globe\n\nAlso: In the data set, there is ‚Äúcultivated meat‚Äù under the category ‚Äúprotein category‚Äù.\n‚Üí filter to only ‚Äúplant-based‚Äù\nLastly, this data set is updated per request. This could be dangerous, because there is no transparent way to see when the data set was updated last and (I am fairly sure) there is no claim to completeness."
  },
  {
    "objectID": "alt-protein.html#first-visualization-ideas",
    "href": "alt-protein.html#first-visualization-ideas",
    "title": "Alt-Protein Companies",
    "section": "",
    "text": "Idea: compare the falling meat consumption with the (hopefully) rising emerging alt-protein companies"
  },
  {
    "objectID": "alt-protein.html#map-chart-to-show-distribution",
    "href": "alt-protein.html#map-chart-to-show-distribution",
    "title": "Alt-Protein Companies",
    "section": "",
    "text": "Implementation:\n\nGrouping the data set by the Country/ Region column\n\ndf_country = df.groupby('Country/Region').size().reset_index(name='Number of Companies per Country')\n\nHere comes the problem: I do not have the latitude nor longitude inside my dataset. My only indicators are the Country Names. I can not plot my chart as seen in the Altair Documentation of a Choropleth Map, I do not have a cloumn with the iso-3166 code which altair uses to perform the lookup on the geoshape.\nI tried to download a csv file containing the iso codes, to merge with my df, but this did not work properly\nWorkaround: I found a really helful Git Hub repository  Github bast . With the help of this code (which firstly transforms the csv with the iso-codes to the name, and then this name to our value!) I could plot my visualization.\n\n## ----!!! Source:  https://github.com/bast/altair-geographic-plots/blob/main/choropleth.ipynb ---- ##\n\ncountries = alt.topo_feature(data.world_110m.url, \"countries\")\n# https://en.wikipedia.org/wiki/ISO_3166-1_numeric\ncountry_codes = pd.read_csv(\n    \"https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv\"\n)\n\nbackground = alt.Chart(countries).mark_geoshape(fill=\"lightgray\")\n\n# we transform twice, first from \"ISO 3166-1 numeric\" to name, then from name to value\nforeground = (\n    alt.Chart(countries)\n    .mark_geoshape()\n    .transform_lookup(\n        lookup=\"id\",\n        from_=alt.LookupData(data=country_codes, key=\"country-code\", fields=[\"name\"]),\n    )\n    .transform_lookup(\n        lookup=\"name\",\n        from_=alt.LookupData(data=df_country, key=\"name\", fields=[\"Number of Companies per Country\"]),\n    )\n    .encode(\n        fill=alt.Color(\n            \"Number of Companies per Country:Q\",\n            scale=alt.Scale(scheme=\"reds\"),\n            title=\"Number of Companies\"\n        ),\n        tooltip=[alt.Tooltip('name:N', title='Country'), alt.Tooltip('Number of Companies per Country:Q', title='Number of Companies')]\n    )\n)\n\nchart = (\n    (background + foreground)\n    .properties(width=700, height=600)\n    .project(\n        type=\"equalEarth\",\n        scale=800,\n        translate=[200,1000],\n    )\n)\n\n\nIn the visualization, I realized some countries were not displayed. This was due to the fact, that some Countries in my df were not cohesive with the names in the csv file. I decided, I will only show a visualization of europe (adjusting the scale and translation) and edit the incorrect names manually.\n\nEuropean countries in df_country affected:\n\nBavaria and Scotland (can be dropped, only one Company in each)\nCzech Republic -&gt; in country_code file: Czechia\nUnited Kingdom -&gt; in country_code file: United Kingdom of Great Britain and Northern Ireland\n\nFinal Chart:"
  },
  {
    "objectID": "alt-protein.html#line-chart-for-founded-companies-per-year",
    "href": "alt-protein.html#line-chart-for-founded-companies-per-year",
    "title": "Alt-Protein Companies",
    "section": "",
    "text": "Implementation:\n\nCleaning the data, dropping non relevant columns and changing the data types\n\n# dropping not interesting cloumns, e.g. website, founders, ...\n\ndf.drop(['Brief Description', 'Animal-Type Analog', 'State', 'City', 'Website', 'Founders'], axis=1, inplace=True)\n\nLIST_CAT = ['Protein Category','Company Focus','Company type','Technology Focus','Product Type','Ingredient Type','Operating Regions','Country/Region']\n\nfor i in LIST_CAT:\n    df[i] = df[i].astype('category')\n\nCreating a new df with companies specialized on alternative proteins, grouped by Year Founded\n\ndf_founded = df[df['Company type'] == 'Specialized (focused on alternative proteins)'].groupby('Year Founded').size().reset_index(name='Number of Companies Founded')\n\nDecission: I will use the data up until 2021, because it fits better with the meat consumption data & fits better in the storyline\n\ndf_founded = df_founded[(df_founded['Year Founded'] &gt;= 2010) & (df_founded['Year Founded'] &lt;= 2021)]\n\n\n\nYear Founded\nNumber of Companies Founded\n\n\n\n\n2010\n18\n\n\n2011\n19\n\n\n2012\n20\n\n\n2013\n24\n\n\n2014\n27\n\n\n2015\n45\n\n\n2016\n54\n\n\n2017\n66\n\n\n2018\n77\n\n\n2019\n109\n\n\n2020\n105\n\n\n2021\n95\n\n\n\n\nPlotting the line chart\n\n# Convert year founded to datetime\n\ndf_founded['Year Founded'] = pd.to_datetime(df_founded['Year Founded'], format='%Y')\n\n# Plotting line chart\n\nline_chart = alt.Chart(df_founded\n).mark_line().encode(\n    x=alt.X('Year Founded').axis(\n        title = \"Year\",\n        titleColor = 'grey',\n        titleAnchor='start',\n        labelAngle = 0,\n        grid = False,\n        tickColor= 'grey'), \n    y= alt.Y('Number of Companies Founded').axis(\n        title ='Number of Companies Founded',\n        titleColor= 'grey',\n        titleAnchor='end',\n        grid = False, \n        tickColor= 'grey', \n    ),\n    strokeWidth = alt.value(2)\n).properties(\n    width = 550,\n    height = 350\n)\nFinal Chart:"
  },
  {
    "objectID": "alt-protein.html#comparison-between-meat-consumption-and-alt-companies-founded",
    "href": "alt-protein.html#comparison-between-meat-consumption-and-alt-companies-founded",
    "title": "Alt-Protein Companies",
    "section": "",
    "text": "Implementation (in the quarto presentation file):\n\nMerging the dataframes of the meat consumption and alt-protein companies founded\n\ndf_merged = pd.merge(df_consumption, df_founded,\n                     left_on='Year', right_on='Year Founded')\n\nDelete one of the ‚ÄúYear‚Äù columns, otherwise it would be double\nUsing the Altair Documentation of a layered chart with dual axis as a reference\n\n# create double axis chart\nbase = alt.Chart(df_merged).encode(\n    x=alt.X('Year:T').axis(\n        title=\"Year\",\n        titleColor='grey',\n        titleAnchor='start',\n        labelAngle=0,\n        grid=False,\n        tickColor='grey',\n        format='%Y'),\n    strokeWidth=alt.value(2)\n).properties(\n    width=750,\n    height=400\n)\n\nline_consumption = base.mark_line(stroke=dark_red).encode(\n    x=alt.X('Year:T').axis(\n        grid=False,\n        titleColor='grey',\n        titleAnchor='start'),\n    y=alt.Y('Consumption per Person:Q').scale(domain=(40, 75)).axis(\n        title='Consumption of Meat per Person in Germany (kg)',\n        titleColor=dark_red,\n        grid=False,\n        titleAnchor='end',\n        titleAngle=270,\n        titleX=50,\n    )\n)\n\nline_founded = base.mark_line(stroke=blue_highlight).encode(\n    x=alt.X('Year:T').axis(\n        grid=False,\n        titleColor='grey',\n        titleAnchor='start'),\n    y=alt.Y('Number of Companies Founded:Q').axis(\n        title='Number of Companies Founded',\n        titleColor=blue_highlight,\n        grid=False,\n        titleAnchor='end'\n    )\n)\n\nNote here: I left out the year 2022, even though there was meat consumption data that year, in both datasets (alt-protein-companies and meat-consumption). Reason for that was the very low Number of Companies founded in the year 2022. My presumtion is, that this is due to the fact that the Good Food Institute Data set is updated on submission. Newer companies were maybe not yet added to the data. Overall, the comparision with another dataset, maybe regarding the consumption of alternative protein products in Germany, would have been a lot more fitting. Sadly, I could not find any open data sets regarding that topic."
  },
  {
    "objectID": "code/pandas-statistics.html",
    "href": "code/pandas-statistics.html",
    "title": "Setup",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.DataFrame({\n    'name': [\"Tom\", \"Lisa\", \"Peter\"],\n    'height': [1.68, 1.93, 1.72],\n    'weight': [48.4, 89.8, 84.2],\n    'id': [1, 2, 3],\n    'city': ['Stuttgart', 'Stuttgart', 'Berlin']\n})\n\ndf['bmi'] = round(df['weight'] / (df['height'] * df['height']), 2)\ndf[\"name\"] = df[\"name\"].astype(\"category\")\ndf['id'] = df['id'].astype(str)"
  },
  {
    "objectID": "code/pandas-statistics.html#mean",
    "href": "code/pandas-statistics.html#mean",
    "title": "Setup",
    "section": "Mean",
    "text": "Mean\n\nWe can calculate simple statistics like the mean\n\n\ndf['height'].mean()\n\n\ndf['height'].mean().round(2)"
  },
  {
    "objectID": "code/pandas-statistics.html#formatted-string-literals",
    "href": "code/pandas-statistics.html#formatted-string-literals",
    "title": "Setup",
    "section": "Formatted string literals",
    "text": "Formatted string literals\n\nPrint the value in nice format (using formatted string literals f‚Äù‚Ä¶‚Äú)\n\n\nprint(f\"The mean of height is {df['height'].mean():.2f}\")"
  },
  {
    "objectID": "code/pandas-statistics.html#median-and-standard-deviation",
    "href": "code/pandas-statistics.html#median-and-standard-deviation",
    "title": "Setup",
    "section": "Median and Standard Deviation",
    "text": "Median and Standard Deviation\n\ndf['height'].median()\n\n\ndf['height'].std()"
  },
  {
    "objectID": "code/pandas-statistics.html#describe",
    "href": "code/pandas-statistics.html#describe",
    "title": "Setup",
    "section": "Describe",
    "text": "Describe\n\ndescribe() shows a quick statistic summary of your numerical data.\n\n\ndf.describe()"
  },
  {
    "objectID": "code/pandas-statistics.html#describe-with-transpose",
    "href": "code/pandas-statistics.html#describe-with-transpose",
    "title": "Setup",
    "section": "Describe with transpose",
    "text": "Describe with transpose\n\ndf.describe().T.round(2)"
  },
  {
    "objectID": "code/pandas-statistics.html#describe-for-specific-columns-with-groupby",
    "href": "code/pandas-statistics.html#describe-for-specific-columns-with-groupby",
    "title": "Setup",
    "section": "Describe for specific columns with groupby",
    "text": "Describe for specific columns with groupby\n\nSummary statistics for numeric variables height and bmi for different levels of the categorical variable city:\n\n\ndf[['height', 'city']].groupby(['city']).describe().round(2).T"
  },
  {
    "objectID": "code/pandas-statistics.html#example",
    "href": "code/pandas-statistics.html#example",
    "title": "Setup",
    "section": "Example",
    "text": "Example\n\nwe can also use describe() for categorical data\n\n\ndf.describe(include=\"category\").T"
  },
  {
    "objectID": "code/pandas-statistics.html#show-unique-levels",
    "href": "code/pandas-statistics.html#show-unique-levels",
    "title": "Setup",
    "section": "Show unique levels",
    "text": "Show unique levels\n\nShow unique levels of a categorical variable and count with value_counts()\n\n\ndf['city'].value_counts()"
  },
  {
    "objectID": "code/pandas-statistics.html#extract-specific-values",
    "href": "code/pandas-statistics.html#extract-specific-values",
    "title": "Setup",
    "section": "Extract specific values",
    "text": "Extract specific values\n\nWe also can extract specific values\n\n\ndf['city'].value_counts().Stuttgart"
  },
  {
    "objectID": "code/pandas-statistics.html#formatted-string-literals-1",
    "href": "code/pandas-statistics.html#formatted-string-literals-1",
    "title": "Setup",
    "section": "Formatted string literals",
    "text": "Formatted string literals\n\nPrint the value in nice format (using formatted string literals f‚Äù‚Ä¶‚Äú)\n\n\ncount_stuttgart = df['city'].value_counts().Stuttgart\n\nprint(f\"There are {count_stuttgart} people from Stuttgart in the data\")"
  },
  {
    "objectID": "code/pandas-statistics.html#statistics-for-specific-columns",
    "href": "code/pandas-statistics.html#statistics-for-specific-columns",
    "title": "Setup",
    "section": "Statistics for specific columns",
    "text": "Statistics for specific columns\n\nExample of for loop to obtain statistics for specific numerical columns\n\n\n# make a list of numerical columns\nlist_num = ['height', 'weight']\n\n\n# calculate median for our list and only show 4 digits, then make a new line (\\n)\nfor i in list_num:\n    print(f'Median of {i} equals {df[i].median():.4} \\n')"
  },
  {
    "objectID": "code/pandas-statistics.html#summary-statistics",
    "href": "code/pandas-statistics.html#summary-statistics",
    "title": "Setup",
    "section": "Summary statistics",
    "text": "Summary statistics\n\nCalculate summary statistics for our list.\n\n\nfor i in list_num:\n    print(f'Column: {i}  \\n  {df[i].describe().round(2)}   \\n')"
  },
  {
    "objectID": "code/pandas-statistics.html#setup",
    "href": "code/pandas-statistics.html#setup",
    "title": "Setup",
    "section": "Setup",
    "text": "Setup\n\n# Pandas needs the module matplotlib to create plots\nimport matplotlib.pyplot as plt\n\n# show plot output in Jupyter Notebook\n%matplotlib inline"
  },
  {
    "objectID": "code/pandas-statistics.html#one-boxplot",
    "href": "code/pandas-statistics.html#one-boxplot",
    "title": "Setup",
    "section": "One boxplot",
    "text": "One boxplot\n\ndf.boxplot(column=['weight']);\n\n\n# obtain plots for our list\nfor i in list_num:\n    df.boxplot(column=[i])\n    plt.title(\"Boxplot for \" + i)\n    plt.show()"
  },
  {
    "objectID": "impact-data.html",
    "href": "impact-data.html",
    "title": "Environmental Impact",
    "section": "",
    "text": "This dataset covers data from approx. 38,700 commercially viable farms in 119 countries and 40 products, representing ~90% of global protein and calorie consumption.\nThe meta-analysis contains six important environmental impact indicators:\n\nland use\nfreshwater withdrawals weighted by local water scarcity\nwater use\nGHG (greenhouse gas)\nacidifying\neutrophying emissions (runoff of excess nutrients into the surrounding environment and waterways, which affect and pollute the ecosystems - measured in grams of phosphate equivalents, PO‚ÇÑeq)\n\nStress-weighted water use is the volume of blue water multiplied by a water-stress index. Its main application related to water use is the potential to contribute to water scarcity and thereby limit the availability of freshwater for human uses and for the environment.\n‚Üí Interesting for the Data-Story: Land Use, Freshwater Use & GHG emissions\n\nIn this study from 2018, Poore & Nemecek compared the mentioned environmental impact of different products based on either the mass of the product (Volume FU) or protein contained (Nutrition NU).\n‚Üí Comparing the products per 100g of protein could be an interesting metric, because most people consume meat or other animal products because of their nutritional value.\n\n\n\nBecause this is a very complex (but well-known) data set I looked for already existing visualizations of the data to get an understanding of possible trends. I found very good visualization ideas on the ‚ÄúOur World in Data‚Äù Website.\nSee the example visualizations here: Our World in Data\n\n\n\n\n\n\nUsing this simple pie chart as a starting point, to give an overview over the overall impact of food on the climate.\nQuote from the paper: ‚ÄúToday‚Äôs food supply chain creates ~13.7 billion metric tons of carbon dioxide equivalents (CO2eq), 26% of anthropogenic (man-made) GHG emissions.‚Äù (Poore and Nemecek 2018)\n\n\n\n\nMy initial idea was to visualize the land use with an proporional area chart.\n\n\n\n\nTo visualize the emissions per 1000 kcal, 1kg and 100g protein per product and highlighting the plant-based products.\n\n\n\n\nTo visualize the distribution of ghg emissions (5th percentile, median,‚Ä¶) per product, I thought a ridgeline plot could be fitting. But because the values where so different (really big values compared to small values) the implementation was very difficult, so I later decided on an easier visualization which conveys the same message (range bar chart).\n\n\n\n\nImplementataion:\n\nCreating a new df with own values out of the study\n\ndf_food = pd.DataFrame({\"Category\": ['non-food', 'food'], \"Percent\": [74, 26], \"Emissions\": ['5,269.2 billion tons CO2eq', '13.7 billion tons CO2eq']})\n\nColors for food and non-```python\nPlotting the pie chart and saving the df\n\nFinal Chart:\n\n\n\n\nImplementation:\n\nImporting the sheet ‚ÄúWeight‚Äù, cleaning the df, dropping some first and last rows with not relevant information\nDefining an array with the names of the products I want to compare (otherwise there are too much, visualization will be cluttered)\n\nproducts_to_select = ['Rice', 'Potatoes', 'Wheat', 'Soymilk','Tofu', 'Bovine Meat (beef herd)', 'Bovine Meat (dairy herd)', 'Pig Meat', 'Poultry Meat', 'Milk', 'Cheese']\n\ndf_weight = df_weight[df_weight['Product'].isin(products_to_select)]\n\nThe data table was not well structured for my analysis, there where no clear coloumn names\n\n\nWith the help of GitHub Copilot I edited the columns to have a Impact Type Prefix, e.g.¬†Land Use_5th pctl\n\nNow I could select the median of the Impact Types I wanted to display\n\ndf_weight = df_weight[['Product', 'Land Use_Median', 'GHG_Median']]\n\ndf_weight = df_weight.rename(columns={'Land Use_Median': 'Land Use', 'GHG_Median': 'Emissions'})\n\nCreating a new column for the impact type and Product Type\n\ndf_weight2 = df_weight.melt(id_vars=['Product'],\n             value_vars =['Land Use', 'Emissions'],\n             var_name='Impact Type',  #neuer Typ\n             value_name='Impact'\n             )\n\n\n\nanimal_products = ['Bovine Meat (beef herd)', 'Bovine Meat (dairy herd)', 'Pig Meat', 'Poultry Meat', 'Cheese', 'Milk']\n\n# Help from CoPiliot\n# Create a new column 'Product Type' that indicates whether each product is an animal product or a plant product\n\ndf_weight2['Product Type'] = df_weight2['Product'].apply(lambda x: 'Animal Products' if x in animal_products else 'Plants')\n\nCleaned data set:\n\n\n\n\nProduct\nImpact Type\nImpact\nProduct Type\n\n\n\n\nRice\nLand Use\n2.15\nPlants\n\n\nPotatoes\nLand Use\n0.82\nPlants\n\n\nPeas\nLand Use\n6.73\nPlants\n\n\nSoymilk\nLand Use\n0.64\nPlants\n\n\nTofu\nLand Use\n3.41\nPlants\n\n\nOlive Oil\nLand Use\n17.29\nPlants\n\n\nTomatoes\nLand Use\n0.17\nPlants\n\n\nBovine Meat (beef herd)\nLand Use\n170.37\nAnimal Products\n\n\nBovine Meat (dairy herd)\nLand Use\n25.94\nAnimal Products\n\n\nLamb & Mutton\nLand Use\n127.41\nAnimal Products\n\n\nPig Meat\nLand Use\n13.44\nAnimal Products\n\n\n\n\nSaving the data and plotting the bar chart\n\nimpact_chart = alt.Chart(df_weight2).mark_bar().encode(\n    x=alt.X('Impact:Q', scale=alt.Scale(domain=[df_weight2['Impact'].min(), df_weight2['Impact'].max()])).sort('-y').axis(   # - ist descending\n        labelAngle = 0, \n        titleAnchor = 'start'),\n    y=alt.Y('Impact Type:N', title=None).axis(\n        labels = False, \n        titleAnchor = 'end',\n        grid = False),       \n    color='Impact Type:N',\n).facet(\n    row=alt.Row('Product:N', sort=product_order, title=None, header=alt.Header(labelAngle=0, labelAlign= 'left')),\n    spacing = 5,  # Set facet label angle to 45 degrees\n)\nFinal Chart:\n\n\n\n\nImplementation:\n\nImporting the sheets ‚ÄúNutritional Units‚Äù cleaning the df, dropping some first and last rows with not relevant information\nDefining an array with the names of the products I want to compare\nRepeating step 3 from the weight sheet - restructuring the coloumn names\nDropping all columns after number 7, because I only want to compare the GHG emissions\n\ndf_nu = df_nu.drop(df_nu.columns[7:], axis=1)\n\nHaving now this table with the percentiles of the ghg emissions:\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\n5th pctl\n10th pctl\nMean\nMedian\n90th pctl\n95th pctl\n\n\n\n\nWheat & Rye (Bread)\n0.265388\n0.295291\n0.586843\n0.474708\n0.863445\n1.147522\n\n\nMaize (Meal)\n0.145937\n0.161415\n0.375898\n0.260918\n0.510779\n0.778331\n\n\nBarley (Beer)\n0.118\n0.14\n0.236\n0.236\n0.328\n0.354\n\n\nOatmeal\n0.304994\n0.324056\n0.945482\n0.987419\n1.555471\n1.639344\n\n\n\n\nChoosing which products to compare and dropping the rest\nCreating new columns to visualize the animal VS plant products and to compare tofu and bovine meat\n\n#Help from CoPiliot\n# Create a new column 'Product Type' that indicates whether each product is an animal product or a plant product\ndf_nu['Product Type'] = df_nu['Product'].apply(lambda x: 'Animal Products' if x in animal_products else 'Plants')\n\n# Create a new column 'Compare' to later define a scale and change the opacity of all the products that are \"No\" in the compare list\ncompare = ['Bovine Meat (dairy herd)' , 'Tofu']\ndf_nu['Compare'] = df_nu['Product'].apply(lambda x: 'Yes' if x in compare else 'No')\n\n# scale for Product Type Colors\ndf_nu['Product Type'] = df_nu['Product Type'].astype('category')\n\nPRODUCT_TYPE_NU = df_nu['Product Type'].cat.categories.to_list()\n\nproduct_colors = alt.Scale(\n    domain=PRODUCT_TYPE_NU,\n    range=['red', 'green']\n)\n\n# scale for Comparison Opacity\nCOMPARE = df_nu['Compare'].cat.categories.to_list()\n\nproduct_opacity = alt.Scale(\n    domain=COMPARE,\n    range=[0.1, 1]\n)\n\nPlotting the range bar chart and showing median points\n\nbar_nu = alt.Chart(df_nu).mark_bar(cornerRadius=10, height=20).encode(\n    x=alt.X('5th pctl:Q').scale(domain=[0, 140]).title('GHG Emissions (kg CO2eq/kg)'),\n    x2='95th pctl:Q',\n    y=alt.Y('Product:N', title='Product'),\n    color=alt.Color('Product Type:N', scale=product_colors) \n).properties(\n    width=800,\n    height=600\n)\n\n# better use median!!! -&gt; corrected in the quarto presentation\nmean_points = alt.Chart(df_nu).mark_point(filled=False, color='black', size=200).encode(\n  x=alt.X('Mean:Q'),\n  y=alt.Y('Product:N'),\n)\nFinal Chart:\n\nAlso: To focus the attention while comparing meat-protein and tofu-protein, I created a simple vertical line chart at the 5th percentile of bovine meat and gave the products which were not in comparison a lower opacity (see in 7, variable product_opacity).\n\n\n\n\n\nPoore, Joseph, and Thomas Nemecek. 2018. ‚ÄúReducing food‚Äôs environmental impacts through producers and consumers.‚Äù Science 360 (6392): 987‚Äì92. https://doi.org/10.1126/science.aaq0216."
  },
  {
    "objectID": "impact-data.html#about-the-data-poore-2018",
    "href": "impact-data.html#about-the-data-poore-2018",
    "title": "Environmental Impact",
    "section": "",
    "text": "This dataset covers data from approx. 38,700 commercially viable farms in 119 countries and 40 products, representing ~90% of global protein and calorie consumption.\nThe meta-analysis contains six important environmental impact indicators:\n\nland use\nfreshwater withdrawals weighted by local water scarcity\nwater use\nGHG (greenhouse gas)\nacidifying\neutrophying emissions (runoff of excess nutrients into the surrounding environment and waterways, which affect and pollute the ecosystems - measured in grams of phosphate equivalents, PO‚ÇÑeq)\n\nStress-weighted water use is the volume of blue water multiplied by a water-stress index. Its main application related to water use is the potential to contribute to water scarcity and thereby limit the availability of freshwater for human uses and for the environment.\n‚Üí Interesting for the Data-Story: Land Use, Freshwater Use & GHG emissions\n\nIn this study from 2018, Poore & Nemecek compared the mentioned environmental impact of different products based on either the mass of the product (Volume FU) or protein contained (Nutrition NU).\n‚Üí Comparing the products per 100g of protein could be an interesting metric, because most people consume meat or other animal products because of their nutritional value."
  },
  {
    "objectID": "impact-data.html#explorative-data-analysis",
    "href": "impact-data.html#explorative-data-analysis",
    "title": "Environmental Impact",
    "section": "",
    "text": "Because this is a very complex (but well-known) data set I looked for already existing visualizations of the data to get an understanding of possible trends. I found very good visualization ideas on the ‚ÄúOur World in Data‚Äù Website.\nSee the example visualizations here: Our World in Data"
  },
  {
    "objectID": "impact-data.html#first-visualization-ideas",
    "href": "impact-data.html#first-visualization-ideas",
    "title": "Environmental Impact",
    "section": "",
    "text": "Using this simple pie chart as a starting point, to give an overview over the overall impact of food on the climate.\nQuote from the paper: ‚ÄúToday‚Äôs food supply chain creates ~13.7 billion metric tons of carbon dioxide equivalents (CO2eq), 26% of anthropogenic (man-made) GHG emissions.‚Äù (Poore and Nemecek 2018)\n\n\n\n\nMy initial idea was to visualize the land use with an proporional area chart.\n\n\n\n\nTo visualize the emissions per 1000 kcal, 1kg and 100g protein per product and highlighting the plant-based products.\n\n\n\n\nTo visualize the distribution of ghg emissions (5th percentile, median,‚Ä¶) per product, I thought a ridgeline plot could be fitting. But because the values where so different (really big values compared to small values) the implementation was very difficult, so I later decided on an easier visualization which conveys the same message (range bar chart)."
  },
  {
    "objectID": "impact-data.html#pie-chart-for-introduction-of-the-problem",
    "href": "impact-data.html#pie-chart-for-introduction-of-the-problem",
    "title": "Environmental Impact",
    "section": "",
    "text": "Implementataion:\n\nCreating a new df with own values out of the study\n\ndf_food = pd.DataFrame({\"Category\": ['non-food', 'food'], \"Percent\": [74, 26], \"Emissions\": ['5,269.2 billion tons CO2eq', '13.7 billion tons CO2eq']})\n\nColors for food and non-```python\nPlotting the pie chart and saving the df\n\nFinal Chart:"
  },
  {
    "objectID": "impact-data.html#bar-chart-comparing-the-impact-types",
    "href": "impact-data.html#bar-chart-comparing-the-impact-types",
    "title": "Environmental Impact",
    "section": "",
    "text": "Implementation:\n\nImporting the sheet ‚ÄúWeight‚Äù, cleaning the df, dropping some first and last rows with not relevant information\nDefining an array with the names of the products I want to compare (otherwise there are too much, visualization will be cluttered)\n\nproducts_to_select = ['Rice', 'Potatoes', 'Wheat', 'Soymilk','Tofu', 'Bovine Meat (beef herd)', 'Bovine Meat (dairy herd)', 'Pig Meat', 'Poultry Meat', 'Milk', 'Cheese']\n\ndf_weight = df_weight[df_weight['Product'].isin(products_to_select)]\n\nThe data table was not well structured for my analysis, there where no clear coloumn names\n\n\nWith the help of GitHub Copilot I edited the columns to have a Impact Type Prefix, e.g.¬†Land Use_5th pctl\n\nNow I could select the median of the Impact Types I wanted to display\n\ndf_weight = df_weight[['Product', 'Land Use_Median', 'GHG_Median']]\n\ndf_weight = df_weight.rename(columns={'Land Use_Median': 'Land Use', 'GHG_Median': 'Emissions'})\n\nCreating a new column for the impact type and Product Type\n\ndf_weight2 = df_weight.melt(id_vars=['Product'],\n             value_vars =['Land Use', 'Emissions'],\n             var_name='Impact Type',  #neuer Typ\n             value_name='Impact'\n             )\n\n\n\nanimal_products = ['Bovine Meat (beef herd)', 'Bovine Meat (dairy herd)', 'Pig Meat', 'Poultry Meat', 'Cheese', 'Milk']\n\n# Help from CoPiliot\n# Create a new column 'Product Type' that indicates whether each product is an animal product or a plant product\n\ndf_weight2['Product Type'] = df_weight2['Product'].apply(lambda x: 'Animal Products' if x in animal_products else 'Plants')\n\nCleaned data set:\n\n\n\n\nProduct\nImpact Type\nImpact\nProduct Type\n\n\n\n\nRice\nLand Use\n2.15\nPlants\n\n\nPotatoes\nLand Use\n0.82\nPlants\n\n\nPeas\nLand Use\n6.73\nPlants\n\n\nSoymilk\nLand Use\n0.64\nPlants\n\n\nTofu\nLand Use\n3.41\nPlants\n\n\nOlive Oil\nLand Use\n17.29\nPlants\n\n\nTomatoes\nLand Use\n0.17\nPlants\n\n\nBovine Meat (beef herd)\nLand Use\n170.37\nAnimal Products\n\n\nBovine Meat (dairy herd)\nLand Use\n25.94\nAnimal Products\n\n\nLamb & Mutton\nLand Use\n127.41\nAnimal Products\n\n\nPig Meat\nLand Use\n13.44\nAnimal Products\n\n\n\n\nSaving the data and plotting the bar chart\n\nimpact_chart = alt.Chart(df_weight2).mark_bar().encode(\n    x=alt.X('Impact:Q', scale=alt.Scale(domain=[df_weight2['Impact'].min(), df_weight2['Impact'].max()])).sort('-y').axis(   # - ist descending\n        labelAngle = 0, \n        titleAnchor = 'start'),\n    y=alt.Y('Impact Type:N', title=None).axis(\n        labels = False, \n        titleAnchor = 'end',\n        grid = False),       \n    color='Impact Type:N',\n).facet(\n    row=alt.Row('Product:N', sort=product_order, title=None, header=alt.Header(labelAngle=0, labelAlign= 'left')),\n    spacing = 5,  # Set facet label angle to 45 degrees\n)\nFinal Chart:"
  },
  {
    "objectID": "impact-data.html#range-bar-chart-for-comparing-ghg-emissions-and-protein",
    "href": "impact-data.html#range-bar-chart-for-comparing-ghg-emissions-and-protein",
    "title": "Environmental Impact",
    "section": "",
    "text": "Implementation:\n\nImporting the sheets ‚ÄúNutritional Units‚Äù cleaning the df, dropping some first and last rows with not relevant information\nDefining an array with the names of the products I want to compare\nRepeating step 3 from the weight sheet - restructuring the coloumn names\nDropping all columns after number 7, because I only want to compare the GHG emissions\n\ndf_nu = df_nu.drop(df_nu.columns[7:], axis=1)\n\nHaving now this table with the percentiles of the ghg emissions:\n\n\n\n\n\n\n\n\n\n\n\n\n\nProduct\n5th pctl\n10th pctl\nMean\nMedian\n90th pctl\n95th pctl\n\n\n\n\nWheat & Rye (Bread)\n0.265388\n0.295291\n0.586843\n0.474708\n0.863445\n1.147522\n\n\nMaize (Meal)\n0.145937\n0.161415\n0.375898\n0.260918\n0.510779\n0.778331\n\n\nBarley (Beer)\n0.118\n0.14\n0.236\n0.236\n0.328\n0.354\n\n\nOatmeal\n0.304994\n0.324056\n0.945482\n0.987419\n1.555471\n1.639344\n\n\n\n\nChoosing which products to compare and dropping the rest\nCreating new columns to visualize the animal VS plant products and to compare tofu and bovine meat\n\n#Help from CoPiliot\n# Create a new column 'Product Type' that indicates whether each product is an animal product or a plant product\ndf_nu['Product Type'] = df_nu['Product'].apply(lambda x: 'Animal Products' if x in animal_products else 'Plants')\n\n# Create a new column 'Compare' to later define a scale and change the opacity of all the products that are \"No\" in the compare list\ncompare = ['Bovine Meat (dairy herd)' , 'Tofu']\ndf_nu['Compare'] = df_nu['Product'].apply(lambda x: 'Yes' if x in compare else 'No')\n\n# scale for Product Type Colors\ndf_nu['Product Type'] = df_nu['Product Type'].astype('category')\n\nPRODUCT_TYPE_NU = df_nu['Product Type'].cat.categories.to_list()\n\nproduct_colors = alt.Scale(\n    domain=PRODUCT_TYPE_NU,\n    range=['red', 'green']\n)\n\n# scale for Comparison Opacity\nCOMPARE = df_nu['Compare'].cat.categories.to_list()\n\nproduct_opacity = alt.Scale(\n    domain=COMPARE,\n    range=[0.1, 1]\n)\n\nPlotting the range bar chart and showing median points\n\nbar_nu = alt.Chart(df_nu).mark_bar(cornerRadius=10, height=20).encode(\n    x=alt.X('5th pctl:Q').scale(domain=[0, 140]).title('GHG Emissions (kg CO2eq/kg)'),\n    x2='95th pctl:Q',\n    y=alt.Y('Product:N', title='Product'),\n    color=alt.Color('Product Type:N', scale=product_colors) \n).properties(\n    width=800,\n    height=600\n)\n\n# better use median!!! -&gt; corrected in the quarto presentation\nmean_points = alt.Chart(df_nu).mark_point(filled=False, color='black', size=200).encode(\n  x=alt.X('Mean:Q'),\n  y=alt.Y('Product:N'),\n)\nFinal Chart:\n\nAlso: To focus the attention while comparing meat-protein and tofu-protein, I created a simple vertical line chart at the 5th percentile of bovine meat and gave the products which were not in comparison a lower opacity (see in 7, variable product_opacity).\n\n\n\n\n\nPoore, Joseph, and Thomas Nemecek. 2018. ‚ÄúReducing food‚Äôs environmental impacts through producers and consumers.‚Äù Science 360 (6392): 987‚Äì92. https://doi.org/10.1126/science.aaq0216."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Urban Butcher",
    "section": "",
    "text": "You can find the complete pdf-file with the Big Idea Worksheet here.\n\n\n\nTo understand my audience - in my case the owner of urban butcher ‚ÄúAlex Menzinger‚Äù - I created a persona with the goals, objectives and challenges.\n\n\n\n\nFor the corporate design and logo of Urban Butcher, I imaged what a modern & young, but not that high-end butchery could look like. To communicate my fictional company and use case efficienty, I choose a very literal name and logo, which conveys the subject of the company, the product, a trendy brand ‚Äúurban‚Äù and the location.\nFor the colors, I wanted to make sure to have a green and red tone to compare plant and animal products. To draw attention and hence implement the data storytelling principles, I also incorporated the ‚Äúblue_highlight‚Äù color."
  },
  {
    "objectID": "intro.html#the-big-idea-worksheet",
    "href": "intro.html#the-big-idea-worksheet",
    "title": "Urban Butcher",
    "section": "",
    "text": "You can find the complete pdf-file with the Big Idea Worksheet here."
  },
  {
    "objectID": "intro.html#persona",
    "href": "intro.html#persona",
    "title": "Urban Butcher",
    "section": "",
    "text": "To understand my audience - in my case the owner of urban butcher ‚ÄúAlex Menzinger‚Äù - I created a persona with the goals, objectives and challenges."
  },
  {
    "objectID": "intro.html#corporate-design",
    "href": "intro.html#corporate-design",
    "title": "Urban Butcher",
    "section": "",
    "text": "For the corporate design and logo of Urban Butcher, I imaged what a modern & young, but not that high-end butchery could look like. To communicate my fictional company and use case efficienty, I choose a very literal name and logo, which conveys the subject of the company, the product, a trendy brand ‚Äúurban‚Äù and the location.\nFor the colors, I wanted to make sure to have a green and red tone to compare plant and animal products. To draw attention and hence implement the data storytelling principles, I also incorporated the ‚Äúblue_highlight‚Äù color."
  },
  {
    "objectID": "meat-consumption.html",
    "href": "meat-consumption.html",
    "title": "Meat Consumption",
    "section": "",
    "text": "Source: Bundesministerium f√ºr Ern√§hrung und Landwirtschaft (BMEL)\nThe german federal ministry of food and agriculture provides a data set regarding production and consumption of meat in germany, as well as trade data from imports and exports of animals.\nüîó To the dataset\n\n\nInteresting metric: ‚ÄúVerzehr pro Kopf‚Äù - the consumption of meat per person and year. After taking a look at the data and the on the website provided visualizations, it is apparent the the consumption of meat per person falls, which supports my point.\nVisualization on the Website of the BMEL: \n‚Üí I think the choosen bar plot visualization here is not ideal. A line graph where max and min values can be shown via points on the graph could provide a clearer and not so cluttered appearance.\n\n\n\n\n\n\n\n\n\n\nImplemention:\n\nImporting the data set from the BMEL, I encountered a problem:\n\n\n# Problem: the years are on different excel sheets\n# get sheet names\nsheet_names = list(df.keys())\n\nOutput:\n['2022',\n '2021',\n '2020',\n '2019',\n '2018',\n '2017',\n '2016',\n '2015',\n '2014',\n '2013',\n '2012',\n '2011',\n '2010',\n 'Dokumentation']\n\nManually, I located where the values I need (consumption per Person) are found in the table layout\nTogether with Copilot, I created a new df where the sheet name is in one column (Year) and the Consumption per Person in the other\n\n# create a new df dictionary without sheet 'Dokumentation'\n\ndfs = pd.read_excel('original-data/versorgungsbilanz-fleisch.xlsx', sheet_name= sheet_names, skiprows=3, skipfooter=8)\n\n\n# initialize empty list for consumption per person\nconsumption = []\n\n# help from Copilot \nfor sheet_names, df in dfs.items():\n    # Extract the value at the first row and first column\n    value = df.iloc[12, 14]\n    # Append the value and the sheet name to the list\n    consumption.append((sheet_names, value))\n\n# Create a new DataFrame from the list\ndf_consumption = pd.DataFrame(consumption, columns=['Year', 'Consumption per Person'])\n\n\n\nYear\nConsumption per Person\n\n\n\n\n2022\n52.186567\n\n\n2021\n56.786586\n\n\n2020\n57.538436\n\n\n2019\n58.998437\n\n\n2018\n61.467405\n\n\n2017\n61.256313\n\n\n\n\nConverting Year to datetime and rounding the consumption per person to 2 decimals\nSaving the df in the cleaned-data folder\nPlotting the basic line chart\n\nline_chart = alt.Chart(df_consumption,\n    title=alt.Title(\n    'Consumption of Meat in Germany falls',\n    subtitle='The per person consumption of meat in Germany has fallen by 8 kg since 2010',\n    subtitleColor= 'grey',\n    )\n).mark_line().encode(\n    x=alt.X('Year:T').axis(\n        title = \"Year\",\n        titleColor = 'grey',\n        titleAnchor='start',\n        labelAngle = 0,\n        grid = False,\n        tickColor= 'grey', \n        format = '%Y'),\n    y= alt.Y('Consumption per Person').scale(domain=(30, 80)).axis(\n        title ='Consumption per Person in kg',\n        titleColor= 'grey',\n        titleAnchor='end', \n        grid = False, \n        tickColor= 'grey', \n    ),\n    strokeWidth = alt.value(2)\n).properties(\n    width = 550,\n    height = 350\n)\n\nTo focus the attention: creating 2 points and a dotted line for the min and max consumption values and an area to visualize the decline of meat consumption\n\n\n\nIn Quarto presentation: To implement the Data Storytelling Principles, I slowly built the chart up (frist sceleton chart, then line graph, first point at max value and label, second point at min point and label, area and label) Element which were not relevant for the current side got a grey color.\n\nFinal Chart(s):"
  },
  {
    "objectID": "meat-consumption.html#explorative-data-analysis",
    "href": "meat-consumption.html#explorative-data-analysis",
    "title": "Meat Consumption",
    "section": "",
    "text": "Interesting metric: ‚ÄúVerzehr pro Kopf‚Äù - the consumption of meat per person and year. After taking a look at the data and the on the website provided visualizations, it is apparent the the consumption of meat per person falls, which supports my point.\nVisualization on the Website of the BMEL: \n‚Üí I think the choosen bar plot visualization here is not ideal. A line graph where max and min values can be shown via points on the graph could provide a clearer and not so cluttered appearance."
  },
  {
    "objectID": "meat-consumption.html#line-graph-to-show-the-consumption-of-meat-in-germany",
    "href": "meat-consumption.html#line-graph-to-show-the-consumption-of-meat-in-germany",
    "title": "Meat Consumption",
    "section": "",
    "text": "Implemention:\n\nImporting the data set from the BMEL, I encountered a problem:\n\n\n# Problem: the years are on different excel sheets\n# get sheet names\nsheet_names = list(df.keys())\n\nOutput:\n['2022',\n '2021',\n '2020',\n '2019',\n '2018',\n '2017',\n '2016',\n '2015',\n '2014',\n '2013',\n '2012',\n '2011',\n '2010',\n 'Dokumentation']\n\nManually, I located where the values I need (consumption per Person) are found in the table layout\nTogether with Copilot, I created a new df where the sheet name is in one column (Year) and the Consumption per Person in the other\n\n# create a new df dictionary without sheet 'Dokumentation'\n\ndfs = pd.read_excel('original-data/versorgungsbilanz-fleisch.xlsx', sheet_name= sheet_names, skiprows=3, skipfooter=8)\n\n\n# initialize empty list for consumption per person\nconsumption = []\n\n# help from Copilot \nfor sheet_names, df in dfs.items():\n    # Extract the value at the first row and first column\n    value = df.iloc[12, 14]\n    # Append the value and the sheet name to the list\n    consumption.append((sheet_names, value))\n\n# Create a new DataFrame from the list\ndf_consumption = pd.DataFrame(consumption, columns=['Year', 'Consumption per Person'])\n\n\n\nYear\nConsumption per Person\n\n\n\n\n2022\n52.186567\n\n\n2021\n56.786586\n\n\n2020\n57.538436\n\n\n2019\n58.998437\n\n\n2018\n61.467405\n\n\n2017\n61.256313\n\n\n\n\nConverting Year to datetime and rounding the consumption per person to 2 decimals\nSaving the df in the cleaned-data folder\nPlotting the basic line chart\n\nline_chart = alt.Chart(df_consumption,\n    title=alt.Title(\n    'Consumption of Meat in Germany falls',\n    subtitle='The per person consumption of meat in Germany has fallen by 8 kg since 2010',\n    subtitleColor= 'grey',\n    )\n).mark_line().encode(\n    x=alt.X('Year:T').axis(\n        title = \"Year\",\n        titleColor = 'grey',\n        titleAnchor='start',\n        labelAngle = 0,\n        grid = False,\n        tickColor= 'grey', \n        format = '%Y'),\n    y= alt.Y('Consumption per Person').scale(domain=(30, 80)).axis(\n        title ='Consumption per Person in kg',\n        titleColor= 'grey',\n        titleAnchor='end', \n        grid = False, \n        tickColor= 'grey', \n    ),\n    strokeWidth = alt.value(2)\n).properties(\n    width = 550,\n    height = 350\n)\n\nTo focus the attention: creating 2 points and a dotted line for the min and max consumption values and an area to visualize the decline of meat consumption\n\n\n\nIn Quarto presentation: To implement the Data Storytelling Principles, I slowly built the chart up (frist sceleton chart, then line graph, first point at max value and label, second point at min point and label, area and label) Element which were not relevant for the current side got a grey color.\n\nFinal Chart(s):"
  }
]